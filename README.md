# Benchmarking d'Algorithmes de Recherche

Projet d'Ã©valuation et comparaison des performances d'algorithmes de recherche (BFS, DFS, ID, A*, IDA*) sur diffÃ©rents problÃ¨mes types.

## ğŸ¯ Objectifs

- ImplÃ©menter plusieurs algorithmes de recherche en Rust
- Tester sur diffÃ©rents problÃ¨mes (Taquin, plus court chemin, etc.)
- Analyser les performances (temps, mÃ©moire, nÅ“uds visitÃ©s)
- Visualiser et comparer les rÃ©sultats avec Python

## ğŸ“Š Algorithmes ImplÃ©mentÃ©s

- **BFS** (Breadth-First Search)
- **DFS** (Depth-First Search)
- **ID** (Iterative Deepening)
- **A\*** (A-Star)
- **IDA\*** (Iterative Deepening A-Star)

## ğŸ§© ProblÃ¨mes Types

1. **Taquin** (Sliding Puzzle)
   - Tailles: 3x3, 4x4
   - Multiples initialisations
   - Heuristiques: Manhattan, Hamming
   - Ã‰tat initial capturÃ© dans les rÃ©sultats JSON

2. **Plus Court Chemin** (Shortest Path)
   - Graphes de diffÃ©rentes tailles (10x10, 100x100, 1000x1000)
   - Tests de scalabilitÃ©
   - Tous les algorithmes supportÃ©s (BFS, DFS, ID, A*, IDA*)

## ğŸš€ Installation et Utilisation

### PrÃ©requis

- Rust 1.70+ (`rustup install stable`)
- Python 3.8+ avec pip

### Installation

#### Option 1 : TÃ©lÃ©charger les binaires prÃ©-compilÃ©s

TÃ©lÃ©chargez les exÃ©cutables et rÃ©sultats depuis les [Releases GitHub](https://github.com/hactazia/benchmarking-rust/releases) :
- `benchmarking-rust-windows-x64.zip` - Windows 64-bit
- `benchmarking-rust-linux-x64.zip` - Linux 64-bit

Chaque archive contient :
- L'exÃ©cutable compilÃ© (`results/bin/`)
- Les rÃ©sultats JSON des benchmarks
- Tous les graphiques et rapports gÃ©nÃ©rÃ©s

#### Option 2 : Compiler depuis les sources

```bash
# Compiler le projet Rust
cargo build --release

# Installer les dÃ©pendances Python
pip install -r requirements.txt
```

### ExÃ©cution des Benchmarks

```bash
# ExÃ©cuter tous les benchmarks
cargo run --release

# ExÃ©cuter un problÃ¨me spÃ©cifique
cargo run --release -- --problem taquin --size 3

# ExÃ©cuter avec un algorithme spÃ©cifique
cargo run --release -- --algorithm astar --problem taquin

# ContrÃ´ler le nombre de threads (0 = auto-dÃ©tection CPU)
cargo run --release -- --threads 8

# Suite complÃ¨te avec script PowerShell
.\run_benchmarks.ps1
```

### Analyse des RÃ©sultats

```bash
# Fusionner plusieurs fichiers de rÃ©sultats
python analysis/merge_results.py results/all.json results/file1.json results/file2.json

# GÃ©nÃ©rer les graphiques et analyses
python analysis/visualize.py results/file.json

# Rapport complet
python analysis/generate_report.py results/file.json
```

## ğŸ“ˆ MÃ©triques MesurÃ©es

- **Temps de calcul** (ms)
- **MÃ©moire utilisÃ©e** (Ko/Mo)
- **Nombre de nÅ“uds visitÃ©s**
- **Nombre de nÅ“uds gÃ©nÃ©rÃ©s**
- **Longueur de la solution**
- **Facteur de branchement effectif**
- **Ã‰tat initial** du problÃ¨me (capturÃ© dans JSON)

## ğŸ“ Structure du Projet

```
benchmarking-rust/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.rs                 # Point d'entrÃ©e
â”‚   â”œâ”€â”€ algorithms/             # Algorithmes de recherche
â”‚   â”‚   â”œâ”€â”€ mod.rs
â”‚   â”‚   â”œâ”€â”€ bfs.rs
â”‚   â”‚   â”œâ”€â”€ dfs.rs
â”‚   â”‚   â”œâ”€â”€ iterative_deepening.rs
â”‚   â”‚   â”œâ”€â”€ astar.rs
â”‚   â”‚   â””â”€â”€ idastar.rs
â”‚   â”œâ”€â”€ problems/               # ProblÃ¨mes Ã  rÃ©soudre
â”‚   â”‚   â”œâ”€â”€ mod.rs
â”‚   â”‚   â”œâ”€â”€ taquin.rs
â”‚   â”‚   â””â”€â”€ shortest_path.rs
â”‚   â”œâ”€â”€ benchmarking/           # Infrastructure de benchmark
â”‚   â”‚   â”œâ”€â”€ mod.rs
â”‚   â”‚   â”œâ”€â”€ metrics.rs
â”‚   â”‚   â””â”€â”€ runner.rs
â”‚   â””â”€â”€ utils/                  # Utilitaires
â”‚       â”œâ”€â”€ mod.rs
â”‚       â””â”€â”€ heuristics.rs
â”œâ”€â”€ analysis/                   # Scripts Python d'analyse
â”‚   â”œâ”€â”€ visualize.py
â”‚   â”œâ”€â”€ generate_report.py
â”‚   â”œâ”€â”€ merge_results.py
â”‚   â””â”€â”€ utils.py
â”œâ”€â”€ results/                    # RÃ©sultats des benchmarks
â”‚   â”œâ”€â”€ *.json                  # DonnÃ©es brutes
â”‚   â”œâ”€â”€ visuals/                # Graphiques gÃ©nÃ©rÃ©s
â”‚   â”‚   â””â”€â”€ <name>/             # Dossier par fichier JSON
â”‚   â”‚       â”œâ”€â”€ time_comparison.png
â”‚   â”‚       â”œâ”€â”€ memory_comparison.png
â”‚   â”‚       â”œâ”€â”€ nodes_comparison.png
â”‚   â”‚       â””â”€â”€ success_rate.png
â”‚   â””â”€â”€ reports/                # Rapports markdown
â”‚       â””â”€â”€ <name>/             # Dossier par fichier JSON
â”‚           â”œâ”€â”€ index.md        # Rapport principal
â”‚           â””â”€â”€ details.md      # DÃ©tails par instance
â”œâ”€â”€ docs/                       # Documentation
â”œâ”€â”€ README.md                   # Documentation principale
â”œâ”€â”€ start.ps1                   # Script PowerShell pour benchmarks
â”œâ”€â”€ start.sh                    # Script Bash pour benchmarks
â”œâ”€â”€ Cargo.toml                  # Configuration du projet Rust
â””â”€â”€ requirements.txt            # DÃ©pendances Python
```

## ğŸ”¬ RÃ©sultats GÃ©nÃ©rÃ©s

Les benchmarks gÃ©nÃ¨rent plusieurs types de fichiers:

### DonnÃ©es JSON (`results/*.json`)
- Temps d'exÃ©cution par algorithme et problÃ¨me
- Utilisation mÃ©moire
- Statistiques sur les nÅ“uds
- QualitÃ© des solutions
- Ã‰tat initial de chaque instance
- Message d'erreur en cas d'Ã©chec (timeout, pas de solution)

### Visualisations (`results/visuals/<name>/`)
- Graphiques de comparaison des temps d'exÃ©cution
- Utilisation mÃ©moire
- NÅ“uds explorÃ©s
- Taux de succÃ¨s

### Rapports Markdown (`results/reports/<name>/`)
- **index.md**: Vue d'ensemble, statistiques agrÃ©gÃ©es, analyses comparatives
- **details.md**: DÃ©tails de chaque instance triÃ©s par problÃ¨me, algorithme et succÃ¨s