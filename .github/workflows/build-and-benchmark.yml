name: Build and Benchmark

on:
  push:
    branches: [ main, master ]
  pull_request:
    branches: [ main, master ]
  workflow_dispatch:

jobs:
  build-and-test:
    strategy:
      matrix:
        os: [windows-latest, ubuntu-latest]
        include:
          - os: windows-latest
            target: x86_64-pc-windows-msvc
            artifact_name: benchmark.exe
            archive_name: benchmarking-rust-windows-x64.zip
          - os: ubuntu-latest
            target: x86_64-unknown-linux-gnu
            artifact_name: benchmark
            archive_name: benchmarking-rust-linux-x64.zip

    runs-on: ${{ matrix.os }}

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Install Rust
      uses: dtolnay/rust-toolchain@stable
      with:
        targets: ${{ matrix.target }}

    - name: Cache Rust dependencies
      uses: actions/cache@v3
      with:
        path: |
          ~/.cargo/bin/
          ~/.cargo/registry/index/
          ~/.cargo/registry/cache/
          ~/.cargo/git/db/
          target/
        key: ${{ runner.os }}-cargo-${{ hashFiles('**/Cargo.lock') }}
        restore-keys: |
          ${{ runner.os }}-cargo-

    - name: Build release
      run: cargo build --release --target ${{ matrix.target }}

    - name: Run tests
      run: cargo test --release --target ${{ matrix.target }}

    - name: Setup Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'

    - name: Cache Python dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-

    - name: Install Python dependencies
      run: pip install -r requirements.txt

    - name: Run benchmarks - Taquin 3x3
      run: cargo run --release --target ${{ matrix.target }} -- --problem taquin --size 3 --iterations 20 --output results/taquin_3x3.json

    - name: Run benchmarks - Taquin 4x4
      run: cargo run --release --target ${{ matrix.target }} -- --problem taquin --size 4 --iterations 5 --output results/taquin_4x4.json

    - name: Run benchmarks - Shortest Path 10x10
      run: cargo run --release --target ${{ matrix.target }} -- --problem shortest-path --size 10 --iterations 10 --output results/shortest_path_10.json

    - name: Run benchmarks - Shortest Path 100x100
      run: cargo run --release --target ${{ matrix.target }} -- --problem shortest-path --size 100 --iterations 10 --output results/shortest_path_100.json

    - name: Run benchmarks - Shortest Path 1000x1000
      run: cargo run --release --target ${{ matrix.target }} -- --problem shortest-path --size 1000 --iterations 5 --output results/shortest_path_1000.json

    - name: Run benchmarks - Random Graph 50
      run: cargo run --release --target ${{ matrix.target }} -- --problem shortest-path-random --size 50 --iterations 10 --output results/shortest_path_random_50.json

    - name: Run benchmarks - Random Graph 200
      run: cargo run --release --target ${{ matrix.target }} -- --problem shortest-path-random --size 200 --iterations 10 --output results/shortest_path_random_200.json

    - name: Run benchmarks - Random Graph 500
      run: cargo run --release --target ${{ matrix.target }} -- --problem shortest-path-random --size 500 --iterations 5 --output results/shortest_path_random_500.json

    - name: Merge results
      run: |
        python analysis/merge_results.py results/shortest_path.json results/shortest_path_10.json results/shortest_path_100.json results/shortest_path_1000.json
        python analysis/merge_results.py results/shortest_path_random.json results/shortest_path_random_50.json results/shortest_path_random_200.json results/shortest_path_random_500.json
        python analysis/merge_results.py results/taquin.json results/taquin_3x3.json results/taquin_4x4.json
        python analysis/merge_results.py results/all.json results/taquin.json results/shortest_path.json results/shortest_path_random.json

    - name: Generate visualizations
      run: python analysis/visualize.py results/

    - name: Generate reports
      run: python analysis/generate_report.py results/

    - name: Copy executable to results
      shell: bash
      run: |
        mkdir -p results/bin
        cp target/${{ matrix.target }}/release/${{ matrix.artifact_name }} results/bin/

    - name: Create archive
      shell: bash
      run: |
        if [ "${{ runner.os }}" == "Windows" ]; then
          7z a ${{ matrix.archive_name }} results/
        else
          zip -r ${{ matrix.archive_name }} results/
        fi

    - name: Upload artifacts
      uses: actions/upload-artifact@v4
      with:
        name: ${{ matrix.os }}-benchmark-results
        path: ${{ matrix.archive_name }}
        retention-days: 30

    - name: Upload results separately
      uses: actions/upload-artifact@v4
      with:
        name: ${{ matrix.os }}-results-json
        path: results/*.json
        retention-days: 30

  create-release:
    needs: build-and-test
    runs-on: ubuntu-latest
    if: github.event_name == 'push' && (github.ref == 'refs/heads/main' || github.ref == 'refs/heads/master')
    
    steps:
    - name: Download all artifacts
      uses: actions/download-artifact@v4

    - name: Display structure
      run: ls -R

    - name: Create Release
      id: create_release
      uses: softprops/action-gh-release@v1
      with:
        tag_name: build-${{ github.run_number }}
        name: Benchmark Build ${{ github.run_number }}
        draft: false
        prerelease: false
        files: |
          windows-latest-benchmark-results/*.zip
          ubuntu-latest-benchmark-results/*.zip
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
